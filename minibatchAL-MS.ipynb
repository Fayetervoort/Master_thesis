{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from time import time\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torcheval.metrics import MulticlassPrecision\n",
    "from torcheval.metrics.classification import MulticlassRecall\n",
    "from torcheval.metrics import MulticlassF1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the amount of labels\n",
    "label_num = 10\n",
    "# set maximum separation setting to True or False\n",
    "ms = True\n",
    "# Adjust number of labels for maximum separation\n",
    "if ms == True:\n",
    "    label_num = label_num - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_num)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"SVHN\"\n",
    "run_name = \"Maximum-Separation-Training\"\n",
    "wandb.init(project=project_name, name=run_name,settings=wandb.Settings(start_method='fork'))\n",
    "wandb.define_metric(\"custom_step\")\n",
    "wandb.define_metric(\n",
    "  \"test/accuracy\", step_metric=\"custom_step\")\n",
    "wandb.define_metric(\n",
    "  \"test_precision\", step_metric=\"custom_step\")\n",
    "wandb.define_metric(\n",
    "  \"test_recall\", step_metric=\"custom_step\")\n",
    "wandb.define_metric(\n",
    "  \"test_f1\", step_metric=\"custom_step\")\n",
    "# wandb.config.update(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the CIFAR-10 dataset\n",
    "#train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "#test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# import the CIFAR-100 dataset\n",
    "#train_set = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "#test_set = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# import the SVHN dataset\n",
    "train_set = torchvision.datasets.SVHN(root='./data', split='train', download=True, transform=transforms.ToTensor())\n",
    "test_set = torchvision.datasets.SVHN(root='./data', split='test', download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, num_classes=label_num):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32*3, 100) # Fully connected layer with 100 hidden neurons\n",
    "        self.fc2 = nn.Linear(100, num_classes) # Fully connected layer with num_classes outputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32*32*3) # reshape the input tensor\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"resnet in pytorch\n",
    "\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.\n",
    "\n",
    "    Deep Residual Learning for Image Recognition\n",
    "    https://arxiv.org/abs/1512.03385v1\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"Basic Block for resnet 18 and resnet 34\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #BasicBlock and BottleNeck block\n",
    "    #have different output size\n",
    "    #we use class attribute expansion\n",
    "    #to distinct\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        #residual function\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "        )\n",
    "\n",
    "        #shortcut\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        #the shortcut output dimension is not the same with residual function\n",
    "        #use 1*1 convolution to match the dimension\n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    \"\"\"Residual block for resnet over 50 layers\n",
    "\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, num_block, num_classes=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True))\n",
    "        #we use a different inputsize than the original paper\n",
    "        #so conv2_x's stride is 1\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        \"\"\"make resnet layers(by layer i didnt mean this 'layer' was the\n",
    "        same as a neuron netowork layer, ex. conv layer), one layer may\n",
    "        contain more than one residual block\n",
    "\n",
    "        Args:\n",
    "            block: block type, basic block or bottle neck block\n",
    "            out_channels: output depth channel number of this layer\n",
    "            num_blocks: how many blocks per layer\n",
    "            stride: the stride of the first block of this layer\n",
    "\n",
    "        Return:\n",
    "            return a resnet layer\n",
    "        \"\"\"\n",
    "\n",
    "        # we have num_block blocks per layer, the first block\n",
    "        # could be 1 or 2, other blocks would always be 1\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        output = self.conv3_x(output)\n",
    "        output = self.conv4_x(output)\n",
    "        output = self.conv5_x(output)\n",
    "        output = self.avg_pool(output)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "def resnet18():\n",
    "    \"\"\" return a ResNet 18 object\n",
    "    \"\"\"\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "def resnet34(dims):\n",
    "    \"\"\" return a ResNet 34 object\n",
    "    \"\"\"\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=dims)\n",
    "\n",
    "def resnet50(dims):\n",
    "    \"\"\" return a ResNet 50 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck, [3, 4, 6, 3], num_classes=dims)\n",
    "\n",
    "def resnet101(dims):\n",
    "    \"\"\" return a ResNet 101 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck, [3, 4, 23, 3], num_classes=dims)\n",
    "\n",
    "def resnet152():\n",
    "    \"\"\" return a ResNet 152 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = resnet34(label_num)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000) #for nr_prototypes>=1000\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prototypes(nr_prototypes):\n",
    "    assert nr_prototypes > 0\n",
    "    prototypes = V(nr_prototypes - 1).T\n",
    "    assert prototypes.shape == (nr_prototypes, nr_prototypes - 1)\n",
    "    assert np.all(np.abs(np.sum(np.power(prototypes, 2), axis=1) - 1) <= 1e-6)\n",
    "    distances = cdist(prototypes, prototypes)\n",
    "    assert distances[~np.eye(*distances.shape, dtype=bool)].std() <= 1e-3\n",
    "    return prototypes.astype(np.float32)\n",
    "\n",
    "def V(order):\n",
    "    if order == 1:\n",
    "        return np.array([[1, -1]])\n",
    "    else:\n",
    "        col1 = np.zeros((order, 1))\n",
    "        col1[0] = 1\n",
    "        row1 = -1 / order * np.ones((1, order))\n",
    "        return np.concatenate((col1, np.concatenate((row1, np.sqrt(1 - 1 / (order**2)) * V(order - 1)), axis=0)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into PyTorch DataLoader\n",
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create prototypes for maximum separation\n",
    "prototypes = create_prototypes(10)\n",
    "prototypes = torch.from_numpy(prototypes).float()\n",
    "prototypes *= 0.1\n",
    "dims = prototypes.shape[1]\n",
    "prototypes = prototypes.t()\n",
    "prototypes = prototypes.to(device)\n",
    "test_prototypes = prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_loader, label_num, ms):\n",
    "    # train the model\n",
    "    num_epochs = 50\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "    metric_p = MulticlassPrecision(average=\"macro\", num_classes=10)\n",
    "    metric_r = MulticlassRecall(average=\"macro\", num_classes=10)\n",
    "    metric_f1 = MulticlassF1Score(average=\"macro\", num_classes=10)\n",
    "\n",
    "\n",
    "    # Loop through the number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        metric_p.reset()\n",
    "        metric_r.reset()\n",
    "        metric_f1.reset()\n",
    "\n",
    "\n",
    "        # set model to train mode\n",
    "        model.train()\n",
    "        n_steps_per_epoch = len(train_loader.dataset) / train_loader.batch_size\n",
    "        # iterate over the training data\n",
    "        for batch_index,(inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to(device)\n",
    "            # Maximum separation\n",
    "            if ms == True:\n",
    "                outputs = torch.mm(outputs, prototypes)\n",
    "            #compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # increment the running loss and accuracy\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        # calculate the average training loss and accuracy\n",
    "        train_loss /= len(train_loader)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc /= len(train_loader.dataset)\n",
    "        train_acc_history.append(train_acc)\n",
    "\n",
    "        wandb.log({\"train/batchwise_loss\": loss.item(),\n",
    "        \"train/lr\": optimizer.param_groups[0][\"lr\"],\n",
    "        \"train/weight_decay\": optimizer.param_groups[0][\"weight_decay\"],\n",
    "        \"train/epoch\": ((batch_index)/ n_steps_per_epoch + epoch),\n",
    "        })\n",
    "\n",
    "\n",
    "        # set the model to evaluation mode\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.to(device)\n",
    "                # Maximum separation\n",
    "                if ms == True:\n",
    "                    outputs = torch.mm(outputs, prototypes)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_acc += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "                # update precision metric\n",
    "                metric_p.to(device)\n",
    "                metric_p.update(outputs.argmax(1), labels)\n",
    "\n",
    "                # update recall metric\n",
    "                metric_r.to(device)\n",
    "                metric_r.update(outputs.argmax(1), labels)\n",
    "\n",
    "                # update F1-score metric\n",
    "                metric_f1.to(device)\n",
    "                metric_f1.update(outputs.argmax(1), labels)\n",
    "\n",
    "\n",
    "        # calculate the average validation loss and accuracy\n",
    "        val_loss /= len(test_loader)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc /= len(test_loader.dataset)\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "        # calculate the precision, recall and F1-score\n",
    "        precision = metric_p.compute()\n",
    "        recall = metric_r.compute()\n",
    "        f1 = metric_f1.compute()\n",
    "\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, train loss: {train_loss:.4f}, train acc: {train_acc:.4f}, val loss: {val_loss:.4f}, val acc: {val_acc:.4f}')\n",
    "\n",
    "    return train_acc, val_acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diverse mini-Batch Active Learning input\n",
    "import random\n",
    "\n",
    "unlabeled_dataset = train_set\n",
    "batch_size = 1000\n",
    "n_iter = 10\n",
    "#use maximum separation\n",
    "#use logits\n",
    "\n",
    "\n",
    "\n",
    "# Create random k number of images\n",
    "randomlist = random.sample(range(0, 73257), batch_size)\n",
    "run1_randomlist = randomlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader from trainset\n",
    "trainset_loader = torch.utils.data.DataLoader(train_set, shuffle = False, batch_size=64, num_workers=2)\n",
    "print(len(trainset_loader.dataset))\n",
    "\n",
    "# Create a sampler that selects the first k number of random images\n",
    "train_sampler = torch.utils.data.Subset(trainset_loader.dataset, randomlist)\n",
    "train_loader = torch.utils.data.DataLoader(train_sampler, shuffle = False, batch_size=64, num_workers=2)\n",
    "print(len(train_loader.dataset))\n",
    "\n",
    "# Select the still unlabeled data and create a DataLoader\n",
    "all_data_list = list(range(0, 73257))\n",
    "unlabeled_data_list = [i for i in all_data_list if i not in randomlist]\n",
    "print(len(unlabeled_data_list))\n",
    "unlabeled_sampler = torch.utils.data.Subset(trainset_loader.dataset, unlabeled_data_list)\n",
    "unlabeled_loader = torch.utils.data.DataLoader(unlabeled_sampler, shuffle = False, batch_size=64, num_workers=2)\n",
    "print(len(unlabeled_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repeat until budget is exhausted\n",
    "\n",
    "acc_train_list = []\n",
    "acc_val_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "\n",
    "for n in range(n_iter):\n",
    "\n",
    "    #Train classifier on all the examples selected so far\n",
    "\n",
    "    train_acc, val_acc, precision, recall, f1 = training(train_loader, label_num, ms)\n",
    "    \n",
    "    wandb.log({\"custom_step\": n+1,\n",
    "               \"test/accuracy\": val_acc,\n",
    "                   \"test_precision\":precision,\n",
    "                   \"test_recall\":recall,\n",
    "                   \"test_f1\": f1})\n",
    "\n",
    "    #Add accuracies of training round\n",
    "    acc_train_list.append(train_acc)\n",
    "    acc_val_list.append(val_acc)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    # Create dictionary that contains informative factor for each unlabeled datapoint\n",
    "    uncert_outputs = {}\n",
    "\n",
    "    # Compute informativeness factor for each unlabeled datapoint per batch\n",
    "    for idx,(inputs,_) in enumerate(unlabeled_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        model.eval()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Add maximum separation\n",
    "        #if ms == True:\n",
    "          #outputs = torch.mm(outputs, prototypes)\n",
    "\n",
    "        # use softmax to get probability distribuition for each datapoint in batch\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        # sort probabilities\n",
    "        prob,_ = torch.sort(probs, descending=True)\n",
    "        # compute difference between highest and second highest probability (= informative factor)\n",
    "        diff = prob.data[:,0] - prob.data[:,1]\n",
    "        idy = 0\n",
    "        for x in diff:\n",
    "            index = (idx*64) + idy\n",
    "            # Save index of each datapoint with given informative factor\n",
    "            uncert_outputs[index] = x\n",
    "            idy += 1\n",
    "\n",
    "    # Select the k most informative unlabeled datapoints\n",
    "    k_dataset = sorted(uncert_outputs, key=uncert_outputs.get, reverse=True)[:batch_size]\n",
    "\n",
    "    # Select all other unlabeled datapoints\n",
    "    remain_set = sorted(uncert_outputs, key=uncert_outputs.get, reverse=True)[batch_size:]\n",
    "\n",
    "    # Obtain label of new k datapoints\n",
    "    k_dataset = torch.utils.data.Subset(unlabeled_loader.dataset, k_dataset)\n",
    "    k_dataset =  torch.utils.data.ConcatDataset([train_loader.dataset, k_dataset])\n",
    "    train_loader = torch.utils.data.DataLoader(k_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Remove new k datapoints from unlabeled dataset\n",
    "    unlabeled_loader = torch.utils.data.Subset(unlabeled_loader.dataset, remain_set)\n",
    "    unlabeled_loader = torch.utils.data.DataLoader(unlabeled_loader, batch_size=64, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
